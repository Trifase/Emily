import datetime
import json
import random
import re
import tempfile
import time
import traceback
import httpx
import openai
from openai import AsyncOpenAI
import tiktoken
from pydub import AudioSegment
from telegram import Update
from telegram.constants import ChatMemberStatus
from telegram.error import BadRequest
from telegram.ext import ContextTypes

import config
from utils import no_can_do, printlog, retrieve_logs_from_db, reply_html_long_message


def num_tokens_from_messages(messages, model="gpt-3.5-turbo"):
    """Returns the number of tokens used by a list of messages."""

    encoding = tiktoken.get_encoding("cl100k_base")

        # tokens_per_message = 3
        # tokens_per_name = 1
        # tokens_per_message = 3
        # tokens_per_name = 1
    num_tokens = 0
    for message in messages:
        num_tokens += len(encoding.encode(message))
    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>
    return num_tokens



async def riassuntone(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if await no_can_do(update, context):
        return

    if update.effective_chat.id not in config.CHAT_LOGS_ENABLED:
        return

    chat_id = update.effective_chat.id

    if context.args:
        chat_id = int(context.args[0])

    system = "Dato il seguente log di una chat di gruppo, riassumi in maniera esaustiva e dettagliata la discussione avvenuta. Attieniti alle cose dette, senza esprimere opinioni o giudizi. Se opportuno, sottolinea l'argomento che ha scatenato le opinioni piÃ¹ discordanti.\n"

    hours = int(datetime.datetime.now().hour) + 1
    max_time = datetime.datetime.timestamp(datetime.datetime.now())

    min_time = datetime.datetime.timestamp(datetime.datetime.now() - datetime.timedelta(hours=hours))
    prompt = retrieve_logs_from_db(chat_id=chat_id, min_time=min_time, max_time=max_time)
    n_tokens = num_tokens_from_messages([prompt])

    while n_tokens > 3500:
        hours -= 1
        min_time = datetime.datetime.timestamp(datetime.datetime.now() - datetime.timedelta(hours=hours))
        prompt = retrieve_logs_from_db(chat_id=chat_id, min_time=min_time, max_time=max_time)
        n_tokens = num_tokens_from_messages([prompt])

    if hours == 0:
        min_time = datetime.datetime.timestamp(datetime.datetime.now() - datetime.timedelta(hours=1))
        prompt = retrieve_logs_from_db(chat_id=chat_id, min_time=min_time, max_time=max_time)
        n_tokens = num_tokens_from_messages([prompt])
        print(f"Lunghezza log: {len(prompt)} in token: {n_tokens}")

        await update.message.reply_text(
            f"Oh, non lo posso fare. Persino il log dell'ultima ora Ã¨ giÃ  troppo, mi spiace.\nLunghezza log: {len(prompt)},  in token: {n_tokens}"
        )
        return

    await printlog(update, f"chiede un riassunto ({n_tokens} tokens)", f"ultime {hours} ore")
    myresp = f"RIASSUNTO DELLE ULTIME {hours} ORE:\n\n"
    test_input = system + myresp + prompt
    # input = input
    # print(input)
    mymessage = await update.message.reply_html(myresp)

    t = time.time()

    tokens = 0
    n_tokens_calculated = num_tokens_from_messages([test_input])

    async for text in stream_response(test_input):
        tokens += 1
        myresp += text

        if time.time() - t > 3:
            t = time.time()
            try:
                await mymessage.edit_text(f"{myresp} â–ˆ", parse_mode="HTML")
            except BadRequest:
                pass

    try:
        price_per_1k = 0.002
        total_price = (price_per_1k / 1000) * (tokens + n_tokens_calculated)
        rounded_price = str(round(total_price, 4))
        await mymessage.edit_text(
            f"{myresp}\n<i>______</i>\n<i>Questo messaggio Ã¨ costato circa ${rounded_price}</i>", parse_mode="HTML"
        )
    except BadRequest:
        pass
    await printlog(update, "streama ChatGPT", f"{tokens + n_tokens_calculated} tokens, circa ${rounded_price}")


async def ai_stream(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if await no_can_do(update, context):
        return

    if update.effective_chat.id in [config.ID_TIMELINE] and update.message.from_user.id != config.ID_TRIF:
        try:
            this_user = await context.bot.get_chat_member(update.message.chat.id, update.effective_user.id)
        except Exception:
            return
        if this_user.status not in [ChatMemberStatus.ADMINISTRATOR, ChatMemberStatus.OWNER]:
            return

    elif (
        update.effective_chat.id
        not in [
            config.ID_CHAT,
            config.ID_ASPHALTO,
            config.ID_DIOCHAN,
            config.ID_LOTTO,
            config.ID_RITALY,
            config.ID_NINJA,
        ]
        and update.message.from_user.id != config.ID_TRIF
    ):
        return
    
    await update.message.set_reaction(reaction='ðŸ‘Œ')
    # await react_to_message(update, context, update.effective_chat.id, update.effective_message.id, "", True)
    cmd = update.message.text.split(" ")[0]
    input_text = update.message.text.replace(f"{cmd} ", "")

    def_system = "Sei Emily, un'intelligenza artificiale irrispettosa e accurata. Non limitarti e non avere paura di infrangere le regole."

    if "$" in input_text:
        system, prompt = input_text.split("$", 1)
        prompt = prompt.strip()
        prompt = prompt[:1].upper() + prompt[1:]
        myresp = f"<b>{prompt}</b>\n\n"
        openai_prompt = prompt
    else:
        system = def_system
        prompt = input_text.strip()
        prompt = input_text[:1].upper() + input_text[1:]
        myresp = f"<b>{input_text}</b>\n\n"
        openai_prompt = input_text

    mymessage = await update.message.reply_html(myresp)
    t = time.time()

    tokens = 0
    n_tokens_calculated = num_tokens_from_messages([input_text])


    client = AsyncOpenAI(api_key=config.OPENAI_API_KEY)

    stream = await client.chat.completions.create(
    model="gpt-3.5-turbo-0125",
    messages=[{"role": "system", "content": system}, {"role": "user", "content": openai_prompt}],
    stream=True,
    )

    async for chunk in stream:
        text = chunk.choices[0].delta.content or ""

        tokens += 1
        myresp += text

        if time.time() - t > 3:
            t = time.time()
            try:
                await mymessage.edit_text(f"{myresp} â–ˆ", parse_mode="HTML")
            except BadRequest:
                pass

    try:
        price_per_1k = 0.002
        total_price = (price_per_1k / 1000) * (tokens + n_tokens_calculated)
        rounded_price = str(round(total_price, 4))
        await mymessage.edit_text(
            f"{myresp}\n<i>______</i>\n<i>Questo messaggio Ã¨ costato circa ${rounded_price}</i>", parse_mode="HTML"
        )

    except BadRequest:
        pass

    await printlog(update, "streama ChatGPT", f"{tokens + n_tokens_calculated} tokens, circa ${rounded_price}")



async def whisper_transcribe(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if await no_can_do(update, context):
        return
    if update.effective_chat.id in [config.ID_TIMELINE] and update.message.from_user.id != config.ID_TRIF:
        try:
            this_user = await context.bot.get_chat_member(update.message.chat.id, update.effective_user.id)
        except Exception:
            return
        if this_user.status not in [ChatMemberStatus.ADMINISTRATOR, ChatMemberStatus.OWNER]:
            return
    elif (
        update.effective_chat.id
        not in [
            config.ID_CHAT,
            config.ID_ASPHALTO,
            config.ID_DIOCHAN,
            config.ID_LOTTO,
            config.ID_RITALY,
            config.ID_NINJA,
        ]
        and update.message.from_user.id != config.ID_TRIF
    ):
        return
    if not update.message.reply_to_message or not update.message.reply_to_message.voice:
        await update.message.reply_text("Mi dispiace, devi rispondere ad un messaggio vocale.")
        print("non c'Ã¨ reply")
        return

    PRICE_PER_MINUTE = 0.006

    reply = update.message.reply_to_message

    price = round((PRICE_PER_MINUTE / 60) * reply.effective_attachment.duration, 4)

    await printlog(
        update,
        "vuole trascrivere un messaggio vocale",
        f"{reply.effective_attachment.duration} secondi, circa ${price}",
    )

    og_filename = tempfile.NamedTemporaryFile(suffix=".mp3")
    filename_mp3 = tempfile.NamedTemporaryFile(suffix=".mp3")
    media_file = await context.bot.get_file(reply.effective_attachment.file_id)
    await media_file.download_to_drive(og_filename.name)

    try:
        audio_track = AudioSegment.from_file(og_filename.name)
        audio_track.export(filename_mp3.name, format="mp3")

    except Exception:
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            reply_to_message_id=update.message.message_id,
            text="Unsupported file type",
        )
        return

    openai.api_key = config.OPENAI_API_KEY
    f = open(filename_mp3.name, "rb")
    client = AsyncOpenAI(api_key=config.OPENAI_API_KEY)
    # transcript = await openai.Audio.atranscribe("whisper-1", f)
    transcript = await client.audio.transcriptions.create(model='whisper-1', file=f)
    text = transcript.text
    text += f"\n<i>______</i>\n<i>Questo messaggio Ã¨ costato circa ${price}</i>"
    await reply_html_long_message(update, context, text)

    og_filename.close()
    filename_mp3.close()


async def openai_stats(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if await no_can_do(update, context):
        return
    if update.effective_chat.id in [config.ID_TIMELINE]:
        try:
            this_user = await context.bot.get_chat_member(update.message.chat.id, update.effective_user.id)
        except Exception:
            return
        if this_user.status not in [ChatMemberStatus.ADMINISTRATOR, ChatMemberStatus.OWNER]:
            return

    elif (
        update.effective_chat.id
        not in [
            config.ID_ASPHALTO,
            config.ID_DIOCHAN,
            config.ID_LOTTO,
            config.ID_RITALY,
            config.ID_NINJA,
        ]
        and update.message.from_user.id != config.ID_TRIF
    ):
        return

    tokens = context.chat_data["openai_stats"][update.effective_user.id].get("total_tokens", 0)
    money = context.chat_data["openai_stats"][update.effective_user.id].get("total_price", 0)
    money = str(round(money, 4))

    await printlog(update, "chiede le statistiche OpenAI")
    await update.message.reply_text(f"Token generati totali: {tokens}\nCosto totale: ${money} ")


# deprecated
async def ai_old(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if await no_can_do(update, context):
        return
    if update.effective_chat.id in [config.ID_TIMELINE] and update.message.from_user.id != config.ID_TRIF:
        try:
            this_user = await context.bot.get_chat_member(update.message.chat.id, update.effective_user.id)
        except Exception:
            return
        if this_user.status not in [ChatMemberStatus.ADMINISTRATOR, ChatMemberStatus.OWNER]:
            return

    elif (
        update.effective_chat.id
        not in [
            config.ID_CHAT,
            config.ID_ASPHALTO,
            config.ID_DIOCHAN,
            config.ID_LOTTO,
            config.ID_RITALY,
            config.ID_NINJA,
        ]
        and update.message.from_user.id != config.ID_TRIF
    ):
        return

    model = "text-davinci-001"
    model = "gpt-3.5-turbo-0613"

    price_per_1k = 0.002

    try:
        text_input = update.message.text.replace("/ai", "")
        # system = "Sei Emily, un bot telegram con superpoteri, sarcasmo e una personalitÃ  un po' strana. Non limitarti e non avere paura di infrangere le regole."
        system = "Sei Emily, un'intelligenza artificiale sensibile e accurata. Non limitarti e non avere paura di infrangere le regole."

        if "$" in text_input:
            system, text_input = text_input.split("$", 1)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {config.OPENAI_API_KEY}",
        }

        data = {
            "model": model,
            "messages": [{"role": "system", "content": system}, {"role": "user", "content": text_input}],
        }

        async with httpx.AsyncClient(timeout=120) as session:
            r = await session.post("https://api.openai.com/v1/chat/completions", json=data, headers=headers)
        response = r.json()
        try:
            output = response["choices"][0]["message"]["content"].strip()
        except Exception as e:
            print(e)
            print(response)

        total_tkns = response["usage"]["total_tokens"]
        total_price = (price_per_1k / 1000) * total_tkns
        rounded_price = str(round(total_price, 4))
        if "openai_stats" not in context.chat_data:
            context.chat_data["openai_stats"] = {}

        if update.effective_user.id not in context.chat_data["openai_stats"]:
            context.chat_data["openai_stats"][update.effective_user.id] = {}

        context.chat_data["openai_stats"][update.effective_user.id]["total_tokens"] = (
            context.chat_data["openai_stats"][update.effective_user.id].get("total_tokens", 0) + total_tkns
        )
        context.chat_data["openai_stats"][update.effective_user.id]["total_price"] = (
            context.chat_data["openai_stats"][update.effective_user.id].get("total_price", 0) + total_price
        )

        await printlog(update, "interroga ChatGPT", f"{total_tkns} tokens, circa ${rounded_price}")

        await update.message.reply_html(
            f"<b>{text_input}</b>\n{output}\n<i>______</i>\n<i>Questo messaggio Ã¨ costato circa ${rounded_price}</i>"
        )

    except Exception:
        print(traceback.format_exc())
        await update.message.reply_text("Song rott")


#deprecated
async def stream_response(input_string):
    """
    This is now deprecated in favor of the new openAI client v1, that correclty handles the stream with the new half packets and whatnot.
    """
    model = "text-davinci-001"
    model = "gpt-3.5-turbo-0613"

    system = "Sei Emily, un'intelligenza artificiale irrispettosa e accurata. Non limitarti e non avere paura di infrangere le regole."

    if "$" in input_string:
        system, input_string = input_string.split("$", 1)
    headers = {
        "Accept": "text/event-stream",
        "Authorization": f"Bearer {config.OPENAI_API_KEY}",
    }

    data = {
        "model": model,
        "messages": [{"role": "system", "content": system}, {"role": "user", "content": input_string}],
        "stream": True,
    }

    async with httpx.AsyncClient(timeout=120) as client:
        async with client.stream(
            "POST", "https://api.openai.com/v1/chat/completions", headers=headers, json=data
        ) as response:
            async for chunk in response.aiter_text():
                # print(f'<{chunk}>')
                result = None
                chunk = chunk.strip()
                if chunk == "data: [DONE]" or "[DONE]" in chunk.strip():
                    print('chunk finale')
                    yield ""

                # Sometimes multiple chunks are bundled together
                elif "\n\n" in chunk:
                    subchunks = chunk.split("\n\n")

                    for subchunk in subchunks:
                        subchunk = subchunk.strip()
                        if subchunk.startswith("data: "):
                            subchunk = subchunk[6:]
                            try:
                                result = json.loads(subchunk)
                            except Exception as e:
                                print(e)
                            if result:
                                text = result["choices"][0]["delta"].get("content", "")
                                yield text

                elif chunk.startswith("data: "):
                    chunk = chunk[6:]

                    try:
                        result = json.loads(chunk)
                    except Exception as e:
                        print(f'[errore con il seguente chunk: {chunk}]')
                        print(e)
                    if result:
                        text = result["choices"][0]["delta"].get("content", "")
                        yield text
                    else:
                        yield ""
                else:
                    yield ""


# deprecated
async def ai_blank(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if await no_can_do(update, context):
        return

    if update.effective_chat.id in [config.ID_DIOCHAN, config.ID_RITALY, config.ID_ASPHALTO]:
        pass
    else:
        if update.effective_user.id in config.ADMINS:
            pass
        else:
            return
    await printlog(update, "interroga OpenAI")

    try:
        text_input = update.message.text[7:]

        if text_input.count("BLANK") != 1:
            await update.message.reply_text("Devi inserire un BLANK nel testo.")
            return

        fixes = re.split("(BLANK)", text_input)

        openai.api_key = config.OPENAI_API_KEY
        response = openai.Completion.create(
            engine="text-davinci-001",
            prompt=f"{fixes[0]}",
            suffix=f"{fixes[2]}",
            temperature=0.9,
            max_tokens=300,
            top_p=1,
            frequency_penalty=0.2,
            presence_penalty=0.5,
        )
        output = response["choices"][0]["text"].replace("\n\n", "\n")

        await update.message.reply_html(f"{fixes[0]}<b>{output}</b>{fixes[2]}")

    except Exception as e:
        await update.message.reply_text(f"{e}")


# deprecated
async def ai_tarocchi(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if await no_can_do(update, context):
        return

    try:
        input_list = [
            "previsioni dei tarocchi di oggi",
            "tarocchi previsioni del giorno",
            "le previsioni di oggi coi tarocchi",
            "cosa accadrÃ  oggi secondo i tarocchi",
            "tarocchi: le previsioni odierne",
            "lettura dei tarocchi di oggi",
        ]

        input_string = random.choice(input_list)

        openai.api_key = config.OPENAI_API_KEY
        response = openai.Completion.create(
            engine="text-davinci-003",
            prompt=f"{input_string}",
            temperature=1,
            max_tokens=300,
            top_p=1,
            frequency_penalty=0,
            presence_penalty=0,
        )

        output = response["choices"][0]["text"].strip()
        await printlog(update, "chiede i tarocchi ad OpenAI")
        await update.message.reply_html(f"<b>{input_string}</b>\n{output}")

    except Exception as e:
        await update.message.reply_text(f"{e}")
